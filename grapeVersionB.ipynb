{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.2; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\1\\PycharmProjects\\pythonProject4\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n",
      "WARNING: You are using pip version 21.1.2; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\1\\PycharmProjects\\pythonProject4\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n",
      "WARNING: You are using pip version 21.1.2; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\1\\PycharmProjects\\pythonProject4\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n",
      "WARNING: You are using pip version 21.1.2; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\1\\PycharmProjects\\pythonProject4\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n",
      "WARNING: You are using pip version 21.1.2; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\1\\PycharmProjects\\pythonProject4\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\users\\1\\pycharmprojects\\pythonproject4\\venv\\lib\\site-packages (2.1.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\1\\pycharmprojects\\pythonproject4\\venv\\lib\\site-packages (from sentence-transformers) (3.6.7)\n",
      "Requirement already satisfied: numpy in c:\\users\\1\\pycharmprojects\\pythonproject4\\venv\\lib\\site-packages (from sentence-transformers) (1.21.5)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in c:\\users\\1\\pycharmprojects\\pythonproject4\\venv\\lib\\site-packages (from sentence-transformers) (4.15.0)\n",
      "Requirement already satisfied: huggingface-hub in c:\\users\\1\\pycharmprojects\\pythonproject4\\venv\\lib\\site-packages (from sentence-transformers) (0.2.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\users\\1\\pycharmprojects\\pythonproject4\\venv\\lib\\site-packages (from sentence-transformers) (1.10.1+cu113)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\1\\pycharmprojects\\pythonproject4\\venv\\lib\\site-packages (from sentence-transformers) (0.1.96)\n",
      "Requirement already satisfied: scipy in c:\\users\\1\\pycharmprojects\\pythonproject4\\venv\\lib\\site-packages (from sentence-transformers) (1.7.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\1\\pycharmprojects\\pythonproject4\\venv\\lib\\site-packages (from sentence-transformers) (1.0.2)\n",
      "Requirement already satisfied: tokenizers>=0.10.3 in c:\\users\\1\\pycharmprojects\\pythonproject4\\venv\\lib\\site-packages (from sentence-transformers) (0.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\1\\pycharmprojects\\pythonproject4\\venv\\lib\\site-packages (from sentence-transformers) (4.62.3)\n",
      "Requirement already satisfied: torchvision in c:\\users\\1\\pycharmprojects\\pythonproject4\\venv\\lib\\site-packages (from sentence-transformers) (0.11.2+cu113)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\1\\pycharmprojects\\pythonproject4\\venv\\lib\\site-packages (from torch>=1.6.0->sentence-transformers) (4.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\1\\pycharmprojects\\pythonproject4\\venv\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2.26.0)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\1\\pycharmprojects\\pythonproject4\\venv\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.0.46)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\1\\pycharmprojects\\pythonproject4\\venv\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\1\\pycharmprojects\\pythonproject4\\venv\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (21.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\1\\pycharmprojects\\pythonproject4\\venv\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\1\\pycharmprojects\\pythonproject4\\venv\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2021.11.10)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\1\\pycharmprojects\\pythonproject4\\venv\\lib\\site-packages (from packaging>=20.0->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.6)\n",
      "Requirement already satisfied: colorama in c:\\users\\1\\pycharmprojects\\pythonproject4\\venv\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.4)\n",
      "Requirement already satisfied: click in c:\\users\\1\\pycharmprojects\\pythonproject4\\venv\\lib\\site-packages (from nltk->sentence-transformers) (8.0.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\1\\pycharmprojects\\pythonproject4\\venv\\lib\\site-packages (from nltk->sentence-transformers) (1.1.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\1\\pycharmprojects\\pythonproject4\\venv\\lib\\site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\1\\pycharmprojects\\pythonproject4\\venv\\lib\\site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\1\\pycharmprojects\\pythonproject4\\venv\\lib\\site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\1\\pycharmprojects\\pythonproject4\\venv\\lib\\site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: six in c:\\users\\1\\pycharmprojects\\pythonproject4\\venv\\lib\\site-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\1\\pycharmprojects\\pythonproject4\\venv\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.0.0)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in c:\\users\\1\\pycharmprojects\\pythonproject4\\venv\\lib\\site-packages (from torchvision->sentence-transformers) (8.4.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": "         Gender  Age at Initial Pathologic Diagnosis  ER Status  PR Status  \\\nA2-A0CM       1                                   40        0.0          0   \nA2-A0D2       1                                   45        0.0          0   \nA2-A0EQ       1                                   64        0.0          0   \nA2-A0EV       1                                   80        1.0          1   \nA2-A0EX       1                                   46        1.0          1   \n...         ...                                  ...        ...        ...   \nC8-A138       1                                   54        1.0          0   \nD8-A142       1                                   74        0.0          0   \nE2-A154       1                                   68        1.0          1   \nE2-A158       1                                   43        0.0          0   \nE2-A15A       1                                   45        1.0          1   \n\n         HER2 Final Status Tumor Node Metastasis  AJCC Stage Converted Stage  \\\nA2-A0CM                0.0     2    0          0   Stage IIA       Stage IIA   \nA2-A0D2                0.0     2    0          0   Stage IIB       Stage IIA   \nA2-A0EQ                1.0     2    0          0   Stage IIA       Stage IIA   \nA2-A0EV                0.0     1    0          0    Stage IA         Stage I   \nA2-A0EX                0.0     3    0          0   Stage IIB       Stage IIB   \n...                    ...   ...  ...        ...         ...             ...   \nC8-A138                1.0     2    2          0   Stage III      Stage IIIA   \nD8-A142                0.0     3    0          0   Stage IIB       Stage IIB   \nE2-A154                0.0     1    0          0     Stage I         Stage I   \nE2-A158                0.0     1    1          0   Stage IIA       Stage IIA   \nE2-A15A                0.0     2    3          0  Stage IIIC      Stage IIIC   \n\n         ... NP_001193600 NP_061134  NP_932347  NP_003593  NP_997203  \\\nA2-A0CM  ...          NaN       NaN   1.153614        NaN        NaN   \nA2-A0D2  ...     0.919136 -1.648856   0.832649        NaN  -8.324969   \nA2-A0EQ  ...    -0.801685       NaN        NaN    3.80231  -6.373934   \nA2-A0EV  ...    -4.966177 -1.471027        NaN  -0.474013 -12.278546   \nA2-A0EX  ...      1.45149 -2.018981   0.877456        NaN        NaN   \n...      ...          ...       ...        ...        ...        ...   \nC8-A138  ...    -3.250913  1.711825  -0.248402        NaN   4.707022   \nD8-A142  ...    -5.107629  -0.97598        NaN   2.508629  -12.33711   \nE2-A154  ...    -3.386203 -2.328692  -2.806642        NaN  -4.733495   \nE2-A158  ...    -0.638364  0.051811   2.509998   7.067839        NaN   \nE2-A15A  ...     1.934078  0.234132   0.949899   2.725896        NaN   \n\n         NP_001191293 NP_775791  NP_004065  NP_068752  NP_219494  \nA2-A0CM           NaN       NaN        NaN        NaN        NaN  \nA2-A0D2     -4.679219       NaN   -1.10665        NaN  -6.941181  \nA2-A0EQ      -1.12316       NaN        NaN        NaN        NaN  \nA2-A0EV    -10.337729 -0.653251        NaN        NaN        NaN  \nA2-A0EX     -6.101005       NaN  -1.726336        NaN        NaN  \n...               ...       ...        ...        ...        ...  \nC8-A138      4.107251  -3.20337   1.971481        NaN        NaN  \nD8-A142      -9.54653 -4.066584        NaN        NaN        NaN  \nE2-A154     -9.584499 -4.786183  -3.103949        NaN        NaN  \nE2-A158      0.378972       NaN        NaN   0.665797        NaN  \nE2-A15A     -3.863634       NaN        NaN   4.072432        NaN  \n\n[80 rows x 12579 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Gender</th>\n      <th>Age at Initial Pathologic Diagnosis</th>\n      <th>ER Status</th>\n      <th>PR Status</th>\n      <th>HER2 Final Status</th>\n      <th>Tumor</th>\n      <th>Node</th>\n      <th>Metastasis</th>\n      <th>AJCC Stage</th>\n      <th>Converted Stage</th>\n      <th>...</th>\n      <th>NP_001193600</th>\n      <th>NP_061134</th>\n      <th>NP_932347</th>\n      <th>NP_003593</th>\n      <th>NP_997203</th>\n      <th>NP_001191293</th>\n      <th>NP_775791</th>\n      <th>NP_004065</th>\n      <th>NP_068752</th>\n      <th>NP_219494</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>A2-A0CM</th>\n      <td>1</td>\n      <td>40</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Stage IIA</td>\n      <td>Stage IIA</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.153614</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>A2-A0D2</th>\n      <td>1</td>\n      <td>45</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Stage IIB</td>\n      <td>Stage IIA</td>\n      <td>...</td>\n      <td>0.919136</td>\n      <td>-1.648856</td>\n      <td>0.832649</td>\n      <td>NaN</td>\n      <td>-8.324969</td>\n      <td>-4.679219</td>\n      <td>NaN</td>\n      <td>-1.10665</td>\n      <td>NaN</td>\n      <td>-6.941181</td>\n    </tr>\n    <tr>\n      <th>A2-A0EQ</th>\n      <td>1</td>\n      <td>64</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Stage IIA</td>\n      <td>Stage IIA</td>\n      <td>...</td>\n      <td>-0.801685</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3.80231</td>\n      <td>-6.373934</td>\n      <td>-1.12316</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>A2-A0EV</th>\n      <td>1</td>\n      <td>80</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Stage IA</td>\n      <td>Stage I</td>\n      <td>...</td>\n      <td>-4.966177</td>\n      <td>-1.471027</td>\n      <td>NaN</td>\n      <td>-0.474013</td>\n      <td>-12.278546</td>\n      <td>-10.337729</td>\n      <td>-0.653251</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>A2-A0EX</th>\n      <td>1</td>\n      <td>46</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Stage IIB</td>\n      <td>Stage IIB</td>\n      <td>...</td>\n      <td>1.45149</td>\n      <td>-2.018981</td>\n      <td>0.877456</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-6.101005</td>\n      <td>NaN</td>\n      <td>-1.726336</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>C8-A138</th>\n      <td>1</td>\n      <td>54</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>Stage III</td>\n      <td>Stage IIIA</td>\n      <td>...</td>\n      <td>-3.250913</td>\n      <td>1.711825</td>\n      <td>-0.248402</td>\n      <td>NaN</td>\n      <td>4.707022</td>\n      <td>4.107251</td>\n      <td>-3.20337</td>\n      <td>1.971481</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>D8-A142</th>\n      <td>1</td>\n      <td>74</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Stage IIB</td>\n      <td>Stage IIB</td>\n      <td>...</td>\n      <td>-5.107629</td>\n      <td>-0.97598</td>\n      <td>NaN</td>\n      <td>2.508629</td>\n      <td>-12.33711</td>\n      <td>-9.54653</td>\n      <td>-4.066584</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>E2-A154</th>\n      <td>1</td>\n      <td>68</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Stage I</td>\n      <td>Stage I</td>\n      <td>...</td>\n      <td>-3.386203</td>\n      <td>-2.328692</td>\n      <td>-2.806642</td>\n      <td>NaN</td>\n      <td>-4.733495</td>\n      <td>-9.584499</td>\n      <td>-4.786183</td>\n      <td>-3.103949</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>E2-A158</th>\n      <td>1</td>\n      <td>43</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Stage IIA</td>\n      <td>Stage IIA</td>\n      <td>...</td>\n      <td>-0.638364</td>\n      <td>0.051811</td>\n      <td>2.509998</td>\n      <td>7.067839</td>\n      <td>NaN</td>\n      <td>0.378972</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.665797</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>E2-A15A</th>\n      <td>1</td>\n      <td>45</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>2</td>\n      <td>3</td>\n      <td>0</td>\n      <td>Stage IIIC</td>\n      <td>Stage IIIC</td>\n      <td>...</td>\n      <td>1.934078</td>\n      <td>0.234132</td>\n      <td>0.949899</td>\n      <td>2.725896</td>\n      <td>NaN</td>\n      <td>-3.863634</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4.072432</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>80 rows Ã— 12579 columns</p>\n</div>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Install required packages.\n",
    "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
    "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
    "!pip install -q torch-cluster -f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
    "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
    "!pip install sentence-transformers\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch_geometric.data import HeteroData, download_url, extract_zip\n",
    "from torch_geometric.transforms import ToUndirected, RandomLinkSplit\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from torch_geometric.data import Data\n",
    "import os.path as osp\n",
    "import inspect\n",
    "import sys\n",
    "import os\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as opt\n",
    "from torch.nn import Parameter\n",
    "\n",
    "# Helper functions for visualization.\n",
    "%matplotlib inline\n",
    "\n",
    "clinical = pd.read_csv('data/clinical_data_breast_cancer.csv', index_col=0)\n",
    "proteomes_orig = pd.read_csv('data/77_cancer_proteomes_CPTAC_itraq.csv')\n",
    "PAM50 = pd.read_csv('data/PAM50_proteins.csv')\n",
    "proteomes = proteomes_orig.drop(['gene_symbol','gene_name'], axis=1)\n",
    "clinical.index = clinical.index.to_series().apply(lambda title : title.split('CGA-')[1])\n",
    "proteomes.rename(columns = proteomes.columns.to_series().apply(lambda title: title.split('.')[0]), inplace=True)\n",
    "\n",
    "#Transpose and organize proteomes data\n",
    "proteomes = proteomes.transpose()\n",
    "proteomes.columns =  proteomes.iloc[0]\n",
    "proteomes.drop('RefSeq_accession_number', axis=0, inplace=True)\n",
    "\n",
    "#Convert gender to numbers\n",
    "def num_gender(gender):\n",
    "    if gender == 'MALE':\n",
    "        return 0\n",
    "    elif gender == 'FEMALE':\n",
    "        return 1\n",
    "    else:\n",
    "        return float('NaN')\n",
    "\n",
    "clinical['Gender'] = clinical['Gender'].apply(lambda gender: num_gender(gender))\n",
    "\n",
    "#Convert status to numbers\n",
    "def num_status(status):\n",
    "    if status == 'Negative':\n",
    "        return 0\n",
    "    elif status == 'Positive':\n",
    "        return 1\n",
    "    else:\n",
    "        return\n",
    "\n",
    "clinical['ER Status'] = clinical['ER Status'].apply(lambda status: num_status(status))\n",
    "clinical['PR Status'] = clinical['PR Status'].apply(lambda status: num_status(status))\n",
    "clinical['HER2 Final Status'] = clinical['HER2 Final Status'].apply(lambda status: num_status(status))\n",
    "\n",
    "#Convert tumor, node, metastasis to numbers\n",
    "clinical['Tumor'] = clinical['Tumor'].apply(lambda tumor: tumor.split('T')[1])\n",
    "clinical['Node'] = clinical['Node'].apply(lambda tumor: tumor.split('N')[1])\n",
    "clinical['Metastasis'] = clinical['Metastasis'].apply(lambda tumor: tumor.split('M')[1])\n",
    "#Remove unused columns\n",
    "clinical.drop('Tumor--T1 Coded', axis=1, inplace=True)\n",
    "clinical.drop('Metastasis-Coded', axis=1, inplace=True)\n",
    "clinical.drop('Node-Coded', axis=1, inplace=True)\n",
    "\n",
    "#Merge clinical data with proteomes data\n",
    "datasetPrim = clinical.merge(proteomes, left_index=True,right_index=True)\n",
    "\n",
    "datasetPrim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "noNaProteasomesColumns= np.array(datasetPrim.dropna(axis=1).columns[24:])\n",
    "columnsOfIntrest = np.insert(noNaProteasomesColumns, 0, 'Metastasis', axis=0)\n",
    "dataset=datasetPrim[columnsOfIntrest]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "        NP_958782 NP_958785 NP_958786 NP_000436\nA2-A0D2  0.107491  0.104164  0.107491  0.097512\nA2-A0EQ  -0.91267 -0.927979 -0.927979 -0.931806\nA2-A0EV  0.452986   0.47259   0.47259  0.458587\nA2-A0EX  1.185108  1.192612   1.18886  1.185108",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>NP_958782</th>\n      <th>NP_958785</th>\n      <th>NP_958786</th>\n      <th>NP_000436</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>A2-A0D2</th>\n      <td>0.107491</td>\n      <td>0.104164</td>\n      <td>0.107491</td>\n      <td>0.097512</td>\n    </tr>\n    <tr>\n      <th>A2-A0EQ</th>\n      <td>-0.91267</td>\n      <td>-0.927979</td>\n      <td>-0.927979</td>\n      <td>-0.931806</td>\n    </tr>\n    <tr>\n      <th>A2-A0EV</th>\n      <td>0.452986</td>\n      <td>0.47259</td>\n      <td>0.47259</td>\n      <td>0.458587</td>\n    </tr>\n    <tr>\n      <th>A2-A0EX</th>\n      <td>1.185108</td>\n      <td>1.192612</td>\n      <td>1.18886</td>\n      <td>1.185108</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasetMini = dataset.iloc[1:5,1:5]\n",
    "datasetMini"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os.path as osp\n",
    "import inspect\n",
    "from torch_geometric.data import Data\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pdb\n",
    "\n",
    "#seems that it will give some random masking of the nodes\n",
    "def get_known_mask(known_prob, edge_num):\n",
    "    known_mask = (torch.FloatTensor(edge_num, 1).uniform_() < known_prob).view(-1)\n",
    "    return known_mask\n",
    "#this seems to be mechanism for dropout of the nodes\n",
    "def mask_edge(edge_index,edge_attr,mask,remove_edge):\n",
    "    edge_index = edge_index.clone().detach()\n",
    "    edge_attr = edge_attr.clone().detach()\n",
    "    if remove_edge:\n",
    "        edge_index = edge_index[:,mask]\n",
    "        edge_attr = edge_attr[mask]\n",
    "    else:\n",
    "        edge_attr[~mask] = 0.\n",
    "    return edge_index, edge_attr\n",
    "\n",
    "#basically we get like adjacency matrix\n",
    "def create_node(df, mode):\n",
    "    if mode == 0: # onehot feature node, all 1 sample node\n",
    "        nrow, ncol = df.shape\n",
    "        feature_ind = np.array(range(ncol))\n",
    "        feature_node = np.zeros((ncol,ncol))\n",
    "        feature_node[np.arange(ncol), feature_ind] = 1\n",
    "        sample_node = [[1]*ncol for i in range(nrow)]\n",
    "        node = sample_node + feature_node.tolist()\n",
    "    elif mode == 1: # onehot sample and feature node\n",
    "        nrow, ncol = df.shape\n",
    "        feature_ind = np.array(range(ncol))\n",
    "        feature_node = np.zeros((ncol,ncol+1))\n",
    "        feature_node[np.arange(ncol), feature_ind+1] = 1\n",
    "        sample_node = np.zeros((nrow,ncol+1))\n",
    "        sample_node[:,0] = 1\n",
    "        node = sample_node.tolist() + feature_node.tolist()\n",
    "    return node\n",
    "#we get edges basically between all nodes on the left relative to the right so it will be bipartitie graph !!\n",
    "def create_edge(df):\n",
    "    n_row, n_col = df.shape\n",
    "    edge_start = []\n",
    "    edge_end = []\n",
    "    for x in range(n_row):\n",
    "        edge_start = edge_start + [x] * n_col # obj\n",
    "        edge_end = edge_end + list(n_row+np.arange(n_col)) # att\n",
    "    edge_start_new = edge_start + edge_end\n",
    "    edge_end_new = edge_end + edge_start\n",
    "    return (edge_start_new, edge_end_new)\n",
    "#the entry in the table is saved as the edge attribute we are doubling its becouse we have bidirectional edge\n",
    "def create_edge_attr(df):\n",
    "    nrow, ncol = df.shape\n",
    "    edge_attr = []\n",
    "    for i in range(nrow):\n",
    "        for j in range(ncol):\n",
    "            edge_attr.append([float(df.iloc[i,j])])\n",
    "    edge_attr = edge_attr + edge_attr\n",
    "    return edge_attr"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#complete function to load data\n",
    "def get_data(df_X, df_y, node_mode, train_edge_prob, split_sample_ratio, split_by, train_y_prob, seed=0, normalize=True):\n",
    "    #I suppose just corner cases for small dataframes\n",
    "    if len(df_y.shape)==1:\n",
    "        df_y = df_y.to_numpy()\n",
    "    elif len(df_y.shape)==2:\n",
    "        df_y = df_y[0].to_numpy()\n",
    "    #simple normalization of features as we see we ignore labels\n",
    "    if normalize:\n",
    "        x = df_X.values\n",
    "        min_max_scaler = preprocessing.MinMaxScaler()\n",
    "        x_scaled = min_max_scaler.fit_transform(x)\n",
    "        df_X = pd.DataFrame(x_scaled)\n",
    "\n",
    "\n",
    "    edge_start, edge_end = create_edge(df_X)\n",
    "    edge_index = torch.tensor([edge_start, edge_end], dtype=int)\n",
    "    edge_attr = torch.tensor(create_edge_attr(df_X), dtype=torch.float)\n",
    "    node_init = create_node(df_X, node_mode)\n",
    "    x = torch.tensor(node_init, dtype=torch.float)\n",
    "    y = torch.tensor(df_y, dtype=torch.float)\n",
    "\n",
    "    #set seed to fix known/unknwon edges\n",
    "    torch.manual_seed(seed)\n",
    "    #keep train_edge_prob of all edges\n",
    "    train_edge_mask = get_known_mask(train_edge_prob, int(edge_attr.shape[0]/2))\n",
    "    double_train_edge_mask = torch.cat((train_edge_mask, train_edge_mask), dim=0)\n",
    "\n",
    "    #mask edges based on the generated train_edge_mask\n",
    "    #train_edge_index is known, test_edge_index in unknwon, i.e. missing\n",
    "    train_edge_index, train_edge_attr = mask_edge(edge_index, edge_attr,\n",
    "                                                double_train_edge_mask, True)\n",
    "    train_labels = train_edge_attr[:int(train_edge_attr.shape[0]/2),0]\n",
    "    test_edge_index, test_edge_attr = mask_edge(edge_index, edge_attr,\n",
    "                                                ~double_train_edge_mask, True)\n",
    "    test_labels = test_edge_attr[:int(test_edge_attr.shape[0]/2),0]\n",
    "    #mask the y-values during training, i.e. how we split the training and test sets\n",
    "    train_y_mask = get_known_mask(train_y_prob, y.shape[0])\n",
    "    test_y_mask = ~train_y_mask\n",
    "\n",
    "    data = Data(x=x, y=y, edge_index=edge_index, edge_attr=edge_attr,\n",
    "            train_y_mask=train_y_mask, test_y_mask=test_y_mask,\n",
    "            train_edge_index=train_edge_index,train_edge_attr=train_edge_attr,\n",
    "            train_edge_mask=train_edge_mask,train_labels=train_labels,\n",
    "            test_edge_index=test_edge_index,test_edge_attr=test_edge_attr,\n",
    "            test_edge_mask=~train_edge_mask,test_labels=test_labels,\n",
    "            df_X=df_X,df_y=df_y,\n",
    "            edge_attr_dim=train_edge_attr.shape[-1],\n",
    "            user_num=df_X.shape[0]\n",
    "            )\n",
    "\n",
    "    if split_sample_ratio > 0.:\n",
    "        if split_by == 'y':\n",
    "            sorted_y, sorted_y_index = torch.sort(torch.reshape(y,(-1,)))\n",
    "        elif split_by == 'random':\n",
    "            sorted_y_index = torch.randperm(y.shape[0])\n",
    "        lower_y_index = sorted_y_index[:int(np.floor(y.shape[0]*split_sample_ratio))]\n",
    "        higher_y_index = sorted_y_index[int(np.floor(y.shape[0]*split_sample_ratio)):]\n",
    "        # here we don't split x, only split edge\n",
    "        # train\n",
    "        half_train_edge_index = train_edge_index[:,:int(train_edge_index.shape[1]/2)];\n",
    "        lower_train_edge_mask = []\n",
    "        for node_index in half_train_edge_index[0]:\n",
    "            if node_index in lower_y_index:\n",
    "                lower_train_edge_mask.append(True)\n",
    "            else:\n",
    "                lower_train_edge_mask.append(False)\n",
    "        lower_train_edge_mask = torch.tensor(lower_train_edge_mask)\n",
    "        double_lower_train_edge_mask = torch.cat((lower_train_edge_mask, lower_train_edge_mask), dim=0)\n",
    "        lower_train_edge_index, lower_train_edge_attr = mask_edge(train_edge_index, train_edge_attr,\n",
    "                                                double_lower_train_edge_mask, True)\n",
    "        lower_train_labels = lower_train_edge_attr[:int(lower_train_edge_attr.shape[0]/2),0]\n",
    "        higher_train_edge_index, higher_train_edge_attr = mask_edge(train_edge_index, train_edge_attr,\n",
    "                                                ~double_lower_train_edge_mask, True)\n",
    "        higher_train_labels = higher_train_edge_attr[:int(higher_train_edge_attr.shape[0]/2),0]\n",
    "        # test\n",
    "        half_test_edge_index = test_edge_index[:,:int(test_edge_index.shape[1]/2)];\n",
    "        lower_test_edge_mask = []\n",
    "        for node_index in half_test_edge_index[0]:\n",
    "            if node_index in lower_y_index:\n",
    "                lower_test_edge_mask.append(True)\n",
    "            else:\n",
    "                lower_test_edge_mask.append(False)\n",
    "        lower_test_edge_mask = torch.tensor(lower_test_edge_mask)\n",
    "        double_lower_test_edge_mask = torch.cat((lower_test_edge_mask, lower_test_edge_mask), dim=0)\n",
    "        lower_test_edge_index, lower_test_edge_attr = mask_edge(test_edge_index, test_edge_attr,\n",
    "                                                double_lower_test_edge_mask, True)\n",
    "        lower_test_labels = lower_test_edge_attr[:int(lower_test_edge_attr.shape[0]/2),0]\n",
    "        higher_test_edge_index, higher_test_edge_attr = mask_edge(test_edge_index, test_edge_attr,\n",
    "                                                ~double_lower_test_edge_mask, True)\n",
    "        higher_test_labels = higher_test_edge_attr[:int(higher_test_edge_attr.shape[0]/2),0]\n",
    "\n",
    "\n",
    "        data.lower_y_index = lower_y_index\n",
    "        data.higher_y_index = higher_y_index\n",
    "        data.lower_train_edge_index = lower_train_edge_index\n",
    "        data.lower_train_edge_attr = lower_train_edge_attr\n",
    "        data.lower_train_labels = lower_train_labels\n",
    "        data.higher_train_edge_index = higher_train_edge_index\n",
    "        data.higher_train_edge_attr = higher_train_edge_attr\n",
    "        data.higher_train_labels = higher_train_labels\n",
    "        data.lower_test_edge_index = lower_test_edge_index\n",
    "        data.lower_test_edge_attr = lower_test_edge_attr\n",
    "        data.lower_test_labels = lower_train_labels\n",
    "        data.higher_test_edge_index = higher_test_edge_index\n",
    "        data.higher_test_edge_attr = higher_test_edge_attr\n",
    "        data.higher_test_labels = higher_test_labels\n",
    "\n",
    "    return data\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}