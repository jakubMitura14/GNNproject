{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.2; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\1\\PycharmProjects\\pythonProject4\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n",
      "WARNING: You are using pip version 21.1.2; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\1\\PycharmProjects\\pythonProject4\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n",
      "WARNING: You are using pip version 21.1.2; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\1\\PycharmProjects\\pythonProject4\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n",
      "WARNING: You are using pip version 21.1.2; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\1\\PycharmProjects\\pythonProject4\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "# Install required packages.\n",
    "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
    "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
    "!pip install -q torch-cluster -f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
    "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
    "\n",
    "# Helper functions for visualization.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "         Gender  Age at Initial Pathologic Diagnosis  ER Status  PR Status  \\\nA2-A0CM       1                                   40        0.0          0   \nA2-A0D2       1                                   45        0.0          0   \nA2-A0EQ       1                                   64        0.0          0   \nA2-A0EV       1                                   80        1.0          1   \nA2-A0EX       1                                   46        1.0          1   \n...         ...                                  ...        ...        ...   \nC8-A138       1                                   54        1.0          0   \nD8-A142       1                                   74        0.0          0   \nE2-A154       1                                   68        1.0          1   \nE2-A158       1                                   43        0.0          0   \nE2-A15A       1                                   45        1.0          1   \n\n         HER2 Final Status Tumor Node Metastasis  AJCC Stage Converted Stage  \\\nA2-A0CM                0.0     2    0          0   Stage IIA       Stage IIA   \nA2-A0D2                0.0     2    0          0   Stage IIB       Stage IIA   \nA2-A0EQ                1.0     2    0          0   Stage IIA       Stage IIA   \nA2-A0EV                0.0     1    0          0    Stage IA         Stage I   \nA2-A0EX                0.0     3    0          0   Stage IIB       Stage IIB   \n...                    ...   ...  ...        ...         ...             ...   \nC8-A138                1.0     2    2          0   Stage III      Stage IIIA   \nD8-A142                0.0     3    0          0   Stage IIB       Stage IIB   \nE2-A154                0.0     1    0          0     Stage I         Stage I   \nE2-A158                0.0     1    1          0   Stage IIA       Stage IIA   \nE2-A15A                0.0     2    3          0  Stage IIIC      Stage IIIC   \n\n         ... NP_001193600 NP_061134  NP_932347  NP_003593  NP_997203  \\\nA2-A0CM  ...          NaN       NaN   1.153614        NaN        NaN   \nA2-A0D2  ...     0.919136 -1.648856   0.832649        NaN  -8.324969   \nA2-A0EQ  ...    -0.801685       NaN        NaN    3.80231  -6.373934   \nA2-A0EV  ...    -4.966177 -1.471027        NaN  -0.474013 -12.278546   \nA2-A0EX  ...      1.45149 -2.018981   0.877456        NaN        NaN   \n...      ...          ...       ...        ...        ...        ...   \nC8-A138  ...    -3.250913  1.711825  -0.248402        NaN   4.707022   \nD8-A142  ...    -5.107629  -0.97598        NaN   2.508629  -12.33711   \nE2-A154  ...    -3.386203 -2.328692  -2.806642        NaN  -4.733495   \nE2-A158  ...    -0.638364  0.051811   2.509998   7.067839        NaN   \nE2-A15A  ...     1.934078  0.234132   0.949899   2.725896        NaN   \n\n         NP_001191293 NP_775791  NP_004065  NP_068752  NP_219494  \nA2-A0CM           NaN       NaN        NaN        NaN        NaN  \nA2-A0D2     -4.679219       NaN   -1.10665        NaN  -6.941181  \nA2-A0EQ      -1.12316       NaN        NaN        NaN        NaN  \nA2-A0EV    -10.337729 -0.653251        NaN        NaN        NaN  \nA2-A0EX     -6.101005       NaN  -1.726336        NaN        NaN  \n...               ...       ...        ...        ...        ...  \nC8-A138      4.107251  -3.20337   1.971481        NaN        NaN  \nD8-A142      -9.54653 -4.066584        NaN        NaN        NaN  \nE2-A154     -9.584499 -4.786183  -3.103949        NaN        NaN  \nE2-A158      0.378972       NaN        NaN   0.665797        NaN  \nE2-A15A     -3.863634       NaN        NaN   4.072432        NaN  \n\n[80 rows x 12579 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Gender</th>\n      <th>Age at Initial Pathologic Diagnosis</th>\n      <th>ER Status</th>\n      <th>PR Status</th>\n      <th>HER2 Final Status</th>\n      <th>Tumor</th>\n      <th>Node</th>\n      <th>Metastasis</th>\n      <th>AJCC Stage</th>\n      <th>Converted Stage</th>\n      <th>...</th>\n      <th>NP_001193600</th>\n      <th>NP_061134</th>\n      <th>NP_932347</th>\n      <th>NP_003593</th>\n      <th>NP_997203</th>\n      <th>NP_001191293</th>\n      <th>NP_775791</th>\n      <th>NP_004065</th>\n      <th>NP_068752</th>\n      <th>NP_219494</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>A2-A0CM</th>\n      <td>1</td>\n      <td>40</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Stage IIA</td>\n      <td>Stage IIA</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.153614</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>A2-A0D2</th>\n      <td>1</td>\n      <td>45</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Stage IIB</td>\n      <td>Stage IIA</td>\n      <td>...</td>\n      <td>0.919136</td>\n      <td>-1.648856</td>\n      <td>0.832649</td>\n      <td>NaN</td>\n      <td>-8.324969</td>\n      <td>-4.679219</td>\n      <td>NaN</td>\n      <td>-1.10665</td>\n      <td>NaN</td>\n      <td>-6.941181</td>\n    </tr>\n    <tr>\n      <th>A2-A0EQ</th>\n      <td>1</td>\n      <td>64</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Stage IIA</td>\n      <td>Stage IIA</td>\n      <td>...</td>\n      <td>-0.801685</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3.80231</td>\n      <td>-6.373934</td>\n      <td>-1.12316</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>A2-A0EV</th>\n      <td>1</td>\n      <td>80</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Stage IA</td>\n      <td>Stage I</td>\n      <td>...</td>\n      <td>-4.966177</td>\n      <td>-1.471027</td>\n      <td>NaN</td>\n      <td>-0.474013</td>\n      <td>-12.278546</td>\n      <td>-10.337729</td>\n      <td>-0.653251</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>A2-A0EX</th>\n      <td>1</td>\n      <td>46</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Stage IIB</td>\n      <td>Stage IIB</td>\n      <td>...</td>\n      <td>1.45149</td>\n      <td>-2.018981</td>\n      <td>0.877456</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-6.101005</td>\n      <td>NaN</td>\n      <td>-1.726336</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>C8-A138</th>\n      <td>1</td>\n      <td>54</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>Stage III</td>\n      <td>Stage IIIA</td>\n      <td>...</td>\n      <td>-3.250913</td>\n      <td>1.711825</td>\n      <td>-0.248402</td>\n      <td>NaN</td>\n      <td>4.707022</td>\n      <td>4.107251</td>\n      <td>-3.20337</td>\n      <td>1.971481</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>D8-A142</th>\n      <td>1</td>\n      <td>74</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Stage IIB</td>\n      <td>Stage IIB</td>\n      <td>...</td>\n      <td>-5.107629</td>\n      <td>-0.97598</td>\n      <td>NaN</td>\n      <td>2.508629</td>\n      <td>-12.33711</td>\n      <td>-9.54653</td>\n      <td>-4.066584</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>E2-A154</th>\n      <td>1</td>\n      <td>68</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Stage I</td>\n      <td>Stage I</td>\n      <td>...</td>\n      <td>-3.386203</td>\n      <td>-2.328692</td>\n      <td>-2.806642</td>\n      <td>NaN</td>\n      <td>-4.733495</td>\n      <td>-9.584499</td>\n      <td>-4.786183</td>\n      <td>-3.103949</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>E2-A158</th>\n      <td>1</td>\n      <td>43</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Stage IIA</td>\n      <td>Stage IIA</td>\n      <td>...</td>\n      <td>-0.638364</td>\n      <td>0.051811</td>\n      <td>2.509998</td>\n      <td>7.067839</td>\n      <td>NaN</td>\n      <td>0.378972</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.665797</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>E2-A15A</th>\n      <td>1</td>\n      <td>45</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>2</td>\n      <td>3</td>\n      <td>0</td>\n      <td>Stage IIIC</td>\n      <td>Stage IIIC</td>\n      <td>...</td>\n      <td>1.934078</td>\n      <td>0.234132</td>\n      <td>0.949899</td>\n      <td>2.725896</td>\n      <td>NaN</td>\n      <td>-3.863634</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4.072432</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>80 rows × 12579 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "\n",
    "clinical = pd.read_csv('data/clinical_data_breast_cancer.csv', index_col=0)\n",
    "proteomes_orig = pd.read_csv('data/77_cancer_proteomes_CPTAC_itraq.csv')\n",
    "PAM50 = pd.read_csv('data/PAM50_proteins.csv')\n",
    "proteomes = proteomes_orig.drop(['gene_symbol','gene_name'], axis=1)\n",
    "clinical.index = clinical.index.to_series().apply(lambda title : title.split('CGA-')[1])\n",
    "proteomes.rename(columns = proteomes.columns.to_series().apply(lambda title: title.split('.')[0]), inplace=True)\n",
    "\n",
    "#Transpose and organize proteomes data\n",
    "proteomes = proteomes.transpose()\n",
    "proteomes.columns =  proteomes.iloc[0]\n",
    "proteomes.drop('RefSeq_accession_number', axis=0, inplace=True)\n",
    "\n",
    "#Convert gender to numbers\n",
    "def num_gender(gender):\n",
    "    if gender == 'MALE':\n",
    "        return 0\n",
    "    elif gender == 'FEMALE':\n",
    "        return 1\n",
    "    else:\n",
    "        return float('NaN')\n",
    "\n",
    "clinical['Gender'] = clinical['Gender'].apply(lambda gender: num_gender(gender))\n",
    "\n",
    "#Convert status to numbers\n",
    "def num_status(status):\n",
    "    if status == 'Negative':\n",
    "        return 0\n",
    "    elif status == 'Positive':\n",
    "        return 1\n",
    "    else:\n",
    "        return\n",
    "\n",
    "clinical['ER Status'] = clinical['ER Status'].apply(lambda status: num_status(status))\n",
    "clinical['PR Status'] = clinical['PR Status'].apply(lambda status: num_status(status))\n",
    "clinical['HER2 Final Status'] = clinical['HER2 Final Status'].apply(lambda status: num_status(status))\n",
    "\n",
    "#Convert tumor, node, metastasis to numbers\n",
    "clinical['Tumor'] = clinical['Tumor'].apply(lambda tumor: tumor.split('T')[1])\n",
    "clinical['Node'] = clinical['Node'].apply(lambda tumor: tumor.split('N')[1])\n",
    "clinical['Metastasis'] = clinical['Metastasis'].apply(lambda tumor: tumor.split('M')[1])\n",
    "#Remove unused columns\n",
    "clinical.drop('Tumor--T1 Coded', axis=1, inplace=True)\n",
    "clinical.drop('Metastasis-Coded', axis=1, inplace=True)\n",
    "clinical.drop('Node-Coded', axis=1, inplace=True)\n",
    "\n",
    "#Merge clinical data with proteomes data\n",
    "dataset = clinical.merge(proteomes, left_index=True,right_index=True)\n",
    "\n",
    "dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "        NP_958782 NP_958785 NP_958786 NP_000436 NP_958781 NP_958780 NP_958783  \\\nA2-A0CM  0.683404  0.694424  0.698098  0.687077  0.687077  0.698098  0.698098   \nA2-A0D2  0.107491  0.104164  0.107491  0.097512  0.104164  0.104164  0.104164   \nA2-A0EQ  -0.91267 -0.927979 -0.927979 -0.931806 -0.927979 -0.927979 -0.927979   \nA2-A0EV  0.452986   0.47259   0.47259  0.458587   0.47259   0.47259   0.47259   \nA2-A0EX  1.185108  1.192612   1.18886  1.185108  1.200116   1.18886   1.18886   \n...           ...       ...       ...       ...       ...       ...       ...   \nC8-A138  2.765081  2.779709  2.779709  2.797995  2.787023  2.779709  2.783366   \nD8-A142  0.538596  0.542211  0.542211  0.534981  0.542211  0.542211  0.542211   \nE2-A154  0.862659  0.870186  0.870186  0.866423  0.870186  0.870186  0.870186   \nE2-A158 -1.086529 -1.095492 -1.095492 -1.095492 -1.095492 -1.093252 -1.093252   \nE2-A15A  2.180123  2.180123  2.180123  2.180123  2.180123  2.180123  2.180123   \n\n        NP_958784 NP_112598 NP_001611  ... NP_001193600 NP_061134 NP_932347  \\\nA2-A0CM  0.698098  -2.65215 -0.984373  ...          NaN       NaN  1.153614   \nA2-A0D2  0.104164 -0.880454 -1.512473  ...     0.919136 -1.648856  0.832649   \nA2-A0EQ -0.927979 -3.071151 -2.278943  ...    -0.801685       NaN       NaN   \nA2-A0EV   0.47259 -0.742871  1.811277  ...    -4.966177 -1.471027       NaN   \nA2-A0EX  1.192612  1.046289  2.138081  ...      1.45149 -2.018981  0.877456   \n...           ...       ...       ...  ...          ...       ...       ...   \nC8-A138  2.783366  2.205538  0.749997  ...    -3.250913  1.711825 -0.248402   \nD8-A142  0.542211 -0.148205   0.26749  ...    -5.107629  -0.97598       NaN   \nE2-A154  0.870186  1.920171  2.349197  ...    -3.386203 -2.328692 -2.806642   \nE2-A158 -1.093252  0.096627 -1.149272  ...    -0.638364  0.051811  2.509998   \nE2-A15A  2.180123  1.911711  0.896216  ...     1.934078  0.234132  0.949899   \n\n        NP_003593  NP_997203 NP_001191293 NP_775791 NP_004065 NP_068752  \\\nA2-A0CM       NaN        NaN          NaN       NaN       NaN       NaN   \nA2-A0D2       NaN  -8.324969    -4.679219       NaN  -1.10665       NaN   \nA2-A0EQ   3.80231  -6.373934     -1.12316       NaN       NaN       NaN   \nA2-A0EV -0.474013 -12.278546   -10.337729 -0.653251       NaN       NaN   \nA2-A0EX       NaN        NaN    -6.101005       NaN -1.726336       NaN   \n...           ...        ...          ...       ...       ...       ...   \nC8-A138       NaN   4.707022     4.107251  -3.20337  1.971481       NaN   \nD8-A142  2.508629  -12.33711     -9.54653 -4.066584       NaN       NaN   \nE2-A154       NaN  -4.733495    -9.584499 -4.786183 -3.103949       NaN   \nE2-A158  7.067839        NaN     0.378972       NaN       NaN  0.665797   \nE2-A15A  2.725896        NaN    -3.863634       NaN       NaN  4.072432   \n\n        NP_219494  \nA2-A0CM       NaN  \nA2-A0D2 -6.941181  \nA2-A0EQ       NaN  \nA2-A0EV       NaN  \nA2-A0EX       NaN  \n...           ...  \nC8-A138       NaN  \nD8-A142       NaN  \nE2-A154       NaN  \nE2-A158       NaN  \nE2-A15A       NaN  \n\n[80 rows x 12553 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>NP_958782</th>\n      <th>NP_958785</th>\n      <th>NP_958786</th>\n      <th>NP_000436</th>\n      <th>NP_958781</th>\n      <th>NP_958780</th>\n      <th>NP_958783</th>\n      <th>NP_958784</th>\n      <th>NP_112598</th>\n      <th>NP_001611</th>\n      <th>...</th>\n      <th>NP_001193600</th>\n      <th>NP_061134</th>\n      <th>NP_932347</th>\n      <th>NP_003593</th>\n      <th>NP_997203</th>\n      <th>NP_001191293</th>\n      <th>NP_775791</th>\n      <th>NP_004065</th>\n      <th>NP_068752</th>\n      <th>NP_219494</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>A2-A0CM</th>\n      <td>0.683404</td>\n      <td>0.694424</td>\n      <td>0.698098</td>\n      <td>0.687077</td>\n      <td>0.687077</td>\n      <td>0.698098</td>\n      <td>0.698098</td>\n      <td>0.698098</td>\n      <td>-2.65215</td>\n      <td>-0.984373</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.153614</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>A2-A0D2</th>\n      <td>0.107491</td>\n      <td>0.104164</td>\n      <td>0.107491</td>\n      <td>0.097512</td>\n      <td>0.104164</td>\n      <td>0.104164</td>\n      <td>0.104164</td>\n      <td>0.104164</td>\n      <td>-0.880454</td>\n      <td>-1.512473</td>\n      <td>...</td>\n      <td>0.919136</td>\n      <td>-1.648856</td>\n      <td>0.832649</td>\n      <td>NaN</td>\n      <td>-8.324969</td>\n      <td>-4.679219</td>\n      <td>NaN</td>\n      <td>-1.10665</td>\n      <td>NaN</td>\n      <td>-6.941181</td>\n    </tr>\n    <tr>\n      <th>A2-A0EQ</th>\n      <td>-0.91267</td>\n      <td>-0.927979</td>\n      <td>-0.927979</td>\n      <td>-0.931806</td>\n      <td>-0.927979</td>\n      <td>-0.927979</td>\n      <td>-0.927979</td>\n      <td>-0.927979</td>\n      <td>-3.071151</td>\n      <td>-2.278943</td>\n      <td>...</td>\n      <td>-0.801685</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3.80231</td>\n      <td>-6.373934</td>\n      <td>-1.12316</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>A2-A0EV</th>\n      <td>0.452986</td>\n      <td>0.47259</td>\n      <td>0.47259</td>\n      <td>0.458587</td>\n      <td>0.47259</td>\n      <td>0.47259</td>\n      <td>0.47259</td>\n      <td>0.47259</td>\n      <td>-0.742871</td>\n      <td>1.811277</td>\n      <td>...</td>\n      <td>-4.966177</td>\n      <td>-1.471027</td>\n      <td>NaN</td>\n      <td>-0.474013</td>\n      <td>-12.278546</td>\n      <td>-10.337729</td>\n      <td>-0.653251</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>A2-A0EX</th>\n      <td>1.185108</td>\n      <td>1.192612</td>\n      <td>1.18886</td>\n      <td>1.185108</td>\n      <td>1.200116</td>\n      <td>1.18886</td>\n      <td>1.18886</td>\n      <td>1.192612</td>\n      <td>1.046289</td>\n      <td>2.138081</td>\n      <td>...</td>\n      <td>1.45149</td>\n      <td>-2.018981</td>\n      <td>0.877456</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-6.101005</td>\n      <td>NaN</td>\n      <td>-1.726336</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>C8-A138</th>\n      <td>2.765081</td>\n      <td>2.779709</td>\n      <td>2.779709</td>\n      <td>2.797995</td>\n      <td>2.787023</td>\n      <td>2.779709</td>\n      <td>2.783366</td>\n      <td>2.783366</td>\n      <td>2.205538</td>\n      <td>0.749997</td>\n      <td>...</td>\n      <td>-3.250913</td>\n      <td>1.711825</td>\n      <td>-0.248402</td>\n      <td>NaN</td>\n      <td>4.707022</td>\n      <td>4.107251</td>\n      <td>-3.20337</td>\n      <td>1.971481</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>D8-A142</th>\n      <td>0.538596</td>\n      <td>0.542211</td>\n      <td>0.542211</td>\n      <td>0.534981</td>\n      <td>0.542211</td>\n      <td>0.542211</td>\n      <td>0.542211</td>\n      <td>0.542211</td>\n      <td>-0.148205</td>\n      <td>0.26749</td>\n      <td>...</td>\n      <td>-5.107629</td>\n      <td>-0.97598</td>\n      <td>NaN</td>\n      <td>2.508629</td>\n      <td>-12.33711</td>\n      <td>-9.54653</td>\n      <td>-4.066584</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>E2-A154</th>\n      <td>0.862659</td>\n      <td>0.870186</td>\n      <td>0.870186</td>\n      <td>0.866423</td>\n      <td>0.870186</td>\n      <td>0.870186</td>\n      <td>0.870186</td>\n      <td>0.870186</td>\n      <td>1.920171</td>\n      <td>2.349197</td>\n      <td>...</td>\n      <td>-3.386203</td>\n      <td>-2.328692</td>\n      <td>-2.806642</td>\n      <td>NaN</td>\n      <td>-4.733495</td>\n      <td>-9.584499</td>\n      <td>-4.786183</td>\n      <td>-3.103949</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>E2-A158</th>\n      <td>-1.086529</td>\n      <td>-1.095492</td>\n      <td>-1.095492</td>\n      <td>-1.095492</td>\n      <td>-1.095492</td>\n      <td>-1.093252</td>\n      <td>-1.093252</td>\n      <td>-1.093252</td>\n      <td>0.096627</td>\n      <td>-1.149272</td>\n      <td>...</td>\n      <td>-0.638364</td>\n      <td>0.051811</td>\n      <td>2.509998</td>\n      <td>7.067839</td>\n      <td>NaN</td>\n      <td>0.378972</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.665797</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>E2-A15A</th>\n      <td>2.180123</td>\n      <td>2.180123</td>\n      <td>2.180123</td>\n      <td>2.180123</td>\n      <td>2.180123</td>\n      <td>2.180123</td>\n      <td>2.180123</td>\n      <td>2.180123</td>\n      <td>1.911711</td>\n      <td>0.896216</td>\n      <td>...</td>\n      <td>1.934078</td>\n      <td>0.234132</td>\n      <td>0.949899</td>\n      <td>2.725896</td>\n      <td>NaN</td>\n      <td>-3.863634</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4.072432</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>80 rows × 12553 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proteomesCols= dataset.columns[26:]\n",
    "proteomsFrame = dataset[proteomesCols]\n",
    "proteomsFrame"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[-0.0782, -0.0681, -0.0714,  ...,     nan,     nan,     nan]])]\n",
      "[tensor([[0.4530, 0.4726, 0.4726,  ...,    nan,    nan,    nan]])]\n",
      "[tensor([[-1.0012, -1.0046, -1.0046,  ...,     nan,     nan,     nan]])]\n",
      "[tensor([[ 1.4076,  1.4076,  1.4103,  ..., -0.9337,     nan,     nan]])]\n",
      "[tensor([[1.1749, 1.1832, 1.1832,  ...,    nan,    nan,    nan]])]\n",
      "[tensor([[1.1013, 1.1013, 1.0978,  ...,    nan,    nan,    nan]])]\n",
      "[tensor([[0.2385, 0.2498, 0.2442,  ...,    nan,    nan,    nan]])]\n",
      "[tensor([[ 1.3952,  1.4089,  1.4123,  ..., -2.3756,     nan,     nan]])]\n",
      "[tensor([[ 0.8627,  0.8702,  0.8702,  ..., -3.1039,     nan,     nan]])]\n",
      "[tensor([[0.3113, 0.2962, 0.2962,  ...,    nan,    nan,    nan]])]\n",
      "[tensor([[-0.4878, -0.4878, -0.4878,  ...,     nan,     nan,     nan]])]\n",
      "[tensor([[ 0.3505,  0.3674,  0.3674,  ..., -1.3938, -3.0571,     nan]])]\n",
      "[tensor([[-1.9478, -1.9527, -1.9552,  ...,     nan,     nan,     nan]])]\n",
      "[tensor([[-1.1017, -1.1088, -1.1088,  ...,  1.4925, -4.0986,     nan]])]\n",
      "[tensor([[-0.3073, -0.3073, -0.3073,  ...,     nan,  0.2912,  0.5281]])]\n",
      "[tensor([[-0.2056, -0.2056, -0.2056,  ...,     nan,     nan,     nan]])]\n",
      "[tensor([[-0.6923, -0.6595, -0.6642,  ...,     nan,     nan,     nan]])]\n",
      "[tensor([[0.5783, 0.5822, 0.5783,  ...,    nan,    nan, 1.1132]])]\n",
      "[tensor([[-0.4964, -0.4985, -0.4964,  ...,     nan,     nan,     nan]])]\n",
      "[tensor([[ 1.1007,  1.1007,  1.1007,  ...,  1.2949, -0.1893, 13.0664]])]\n",
      "[tensor([[1.4667, 1.4823, 1.4745,  ...,    nan,    nan,    nan]])]\n",
      "[tensor([[-0.6598, -0.6487, -0.6543,  ...,     nan, -1.9652, -2.8548]])]\n",
      "[tensor([[-0.2650, -0.2516, -0.2516,  ...,     nan,     nan,     nan]])]\n",
      "[tensor([[-1.1232, -1.1232, -1.1169,  ...,     nan,     nan,     nan]])]\n",
      "[tensor([[0.3846, 0.3714, 0.3714,  ..., 1.7371, 0.3615, 0.1438]])]\n",
      "[tensor([[ 0.4611,  0.4611,  0.4611,  ...,     nan,     nan, -1.1773]])]\n",
      "[tensor([[-0.7598, -0.7598, -0.7491,  ...,     nan,     nan, -5.3675]])]\n",
      "[tensor([[-0.4941, -0.5039, -0.5006,  ..., -0.1497,     nan, -0.0480]])]\n",
      "[tensor([[ 0.1402,  0.1261,  0.1331,  ...,     nan, -1.2797,     nan]])]\n",
      "[tensor([[0.6834, 0.6944, 0.6981,  ...,    nan,    nan,    nan]])]\n",
      "[tensor([[ 1.0961,  1.1114,  1.1114,  ...,     nan, -0.6335, 12.6665]])]\n",
      "[tensor([[0.3237, 0.3270, 0.3270,  ...,    nan,    nan,    nan]])]\n",
      "[tensor([[ 0.5689,  0.5689,  0.5689,  ...,     nan, -0.0545, -3.4365]])]\n",
      "[tensor([[ 0.0638,  0.0933,  0.0845,  ..., -4.8014, -2.5905, -6.7404]])]\n",
      "[tensor([[-0.7872, -0.7559, -0.7559,  ..., -4.3752,     nan,     nan]])]\n",
      "[tensor([[ 1.0490,  1.0523,  1.0523,  ..., -1.3518,  2.8759,     nan]])]\n",
      "[tensor([[-0.3986, -0.3926, -0.3926,  ...,     nan,     nan,     nan]])]\n",
      "[tensor([[-0.5184, -0.5100, -0.5072,  ...,     nan,     nan,     nan]])]\n",
      "[tensor([[ 1.2792,  1.2752,  1.2752,  ...,     nan, -1.3202,     nan]])]\n",
      "[tensor([[ -0.5834,  -0.5725,  -0.5671,  ...,      nan,  -2.1365, -10.0080]])]\n",
      "[tensor([[0.5598, 0.5634, 0.5598,  ...,    nan,    nan,    nan]])]\n",
      "[tensor([[-0.5522, -0.5477, -0.5522,  ...,     nan,     nan,     nan]])]\n",
      "[tensor([[0.5386, 0.5422, 0.5422,  ...,    nan,    nan,    nan]])]\n",
      "[tensor([[0.6558, 0.6581, 0.6558,  ...,    nan,    nan,    nan]])]\n",
      "[tensor([[-0.2049, -0.1624, -0.1667,  ...,     nan,     nan,     nan]])]\n",
      "[tensor([[ 1.1205,  1.1376,  1.1376,  ...,     nan,     nan, -8.9540]])]\n",
      "[tensor([[2.1801, 2.1801, 2.1801,  ...,    nan, 4.0724,    nan]])]\n",
      "[tensor([[2.4551, 2.4801, 2.4801,  ...,    nan,    nan,    nan]])]\n",
      "[tensor([[ 1.0532,  1.0559,  1.0559,  ...,  0.7537, -5.0114,     nan]])]\n",
      "[tensor([[-1.5233, -1.5126, -1.5100,  ...,     nan, -4.0345,     nan]])]\n",
      "[tensor([[-1.5143, -1.5283, -1.5283,  ...,  2.0407,     nan,     nan]])]\n",
      "[tensor([[ 0.8311,  0.8565,  0.8565,  ...,     nan,     nan, -3.7536]])]\n",
      "[tensor([[-0.0332, -0.0302, -0.0272,  ...,     nan,     nan,     nan]])]\n",
      "[tensor([[-0.4282, -0.4064, -0.4064,  ...,     nan,     nan,     nan]])]\n",
      "[tensor([[0.7940, 0.8182, 0.8147,  ...,    nan, 1.1813,    nan]])]\n",
      "[tensor([[1.8740, 1.8704, 1.8704,  ...,    nan, 0.6720, 5.1056]])]\n",
      "[tensor([[ 1.1851,  1.1926,  1.1889,  ..., -1.7263,     nan,     nan]])]\n",
      "[tensor([[ 0.7620,  0.7620,  0.7664,  ...,     nan, -2.0068,     nan]])]\n",
      "[tensor([[ 0.0200,  0.0120,  0.0120,  ..., -0.3383,  2.7012,  0.6561]])]\n",
      "[tensor([[2.7651, 2.7797, 2.7797,  ..., 1.9715,    nan,    nan]])]\n",
      "[tensor([[ 0.7572,  0.7809,  0.7741,  ..., -0.2916,     nan,     nan]])]\n",
      "[tensor([[ 0.9736,  0.9775,  0.9775,  ...,     nan,     nan, -3.2669]])]\n",
      "[tensor([[ 0.1075,  0.1042,  0.1075,  ..., -1.1067,     nan, -6.9412]])]\n",
      "[tensor([[ 0.6739,  0.6887,  0.6887,  ..., -0.3371,     nan,     nan]])]\n",
      "[tensor([[-0.1067, -0.1067, -0.1067,  ...,     nan,     nan,     nan]])]\n",
      "[tensor([[-0.0658, -0.0559, -0.0658,  ...,     nan,     nan,     nan]])]\n",
      "[tensor([[2.6099, 2.6504, 2.6504,  ...,    nan, 4.8403, 0.1407]])]\n",
      "[tensor([[0.2649, 0.2757, 0.2757,  ...,    nan,    nan,    nan]])]\n",
      "[tensor([[ 0.1959,  0.1959,  0.1959,  ...,     nan, -6.0644,  0.5648]])]\n",
      "[tensor([[0.8188, 0.8149, 0.8149,  ...,    nan,    nan,    nan]])]\n",
      "[tensor([[1.2225, 1.2190, 1.2225,  ..., 1.5405,    nan, 0.9327]])]\n",
      "[tensor([[-1.0865, -1.0955, -1.0955,  ...,     nan,  0.6658,     nan]])]\n",
      "[tensor([[-0.9127, -0.9280, -0.9280,  ...,     nan,     nan,     nan]])]\n",
      "[tensor([[-0.5114, -0.5261, -0.5261,  ...,     nan,     nan, -1.9833]])]\n",
      "[tensor([[1.5020, 1.5103, 1.5020,  ...,    nan,    nan,    nan]])]\n",
      "[tensor([[ 0.1953,  0.2154,  0.2154,  ..., -1.7784,     nan, -3.0698]])]\n",
      "[tensor([[-0.9639, -0.9382, -0.9439,  ...,     nan,     nan, -6.0029]])]\n",
      "[tensor([[2.7073, 2.7338, 2.7376,  ...,    nan, 2.0275,    nan]])]\n",
      "[tensor([[-0.4816, -0.4779, -0.4816,  ...,  1.0265,     nan,  0.7447]])]\n",
      "[tensor([[ 0.5837,  0.5806,  0.5806,  ..., -1.2642, -1.1004, -5.5903]])]\n"
     ]
    }
   ],
   "source": [
    "#pass dataframe into pytorch dataset from https://towardsdatascience.com/deep-learning-on-dataframes-with-pytorch-66b21be54ef6\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from pandas.api.types import is_string_dtype, is_numeric_dtype\n",
    "import warnings\n",
    "from pdb import set_trace\n",
    "from torch import nn, optim, as_tensor\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.init import *\n",
    "\n",
    "class ColumnarDataset(Dataset):\n",
    "    \"\"\"Dataset class for column dataset.\n",
    "    Args:\n",
    "       cats (list of str): List of the name of columns contain\n",
    "                           categorical variables.\n",
    "       conts (list of str): List of the name of columns which\n",
    "                           contain continuous variables.\n",
    "       y (Tensor, optional): Target variables.\n",
    "       is_reg (bool): If the task is regression, set ``True``,\n",
    "                      otherwise (classification) ``False``.\n",
    "       is_multi (bool): If the task is multi-label classification,\n",
    "                        set ``True``.\n",
    "    \"\"\"\n",
    "    def __init__(self, df):\n",
    "        df_cont = df\n",
    "        conts = [c.values for n,c in df_cont.items()]\n",
    "\n",
    "\n",
    "        self.conts = np.stack(conts, 1).astype(np.float32)\n",
    "                           # if conts else np.zeros((n,1))\n",
    "\n",
    "    def __len__(self): return len(self.conts)\n",
    "    def __getitem__(self, idx):\n",
    "        return [self.conts[idx]]\n",
    "\n",
    "\n",
    "datasetPyTorch = ColumnarDataset(proteomsFrame)\n",
    "train_loader = torch.utils.data.DataLoader(datasetPyTorch, batch_size=1, shuffle=True)\n",
    "for data in train_loader:\n",
    "\tprint(data)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "#getting only columns with no Na values\n",
    "noNaProteasomes= torch.tensor(proteomsFrame.dropna(axis=1).astype('float32').values)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[15, 78,  1,  ..., 64,  8, 27],\n        [ 0,  0,  0,  ..., 79, 79, 79]])"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_cluster import knn_graph\n",
    "edge_index = knn_graph(noNaProteasomes, k=18, loop=False)\n",
    "edge_index"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "from torch.nn import Sequential, Linear, ReLU\n",
    "from torch_geometric.nn import MessagePassing\n",
    "\n",
    "\n",
    "class PointNetLayer(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        # Message passing with \"max\" aggregation.\n",
    "        super().__init__(aggr='max')\n",
    "\n",
    "        # Initialization of the MLP:\n",
    "        # Here, the number of input features correspond to the hidden node\n",
    "        # dimensionality plus point dimensionality (=3).\n",
    "        self.mlp = Sequential(Linear(in_channels + 3, out_channels),\n",
    "                              ReLU(),\n",
    "                              Linear(out_channels, out_channels))\n",
    "\n",
    "    def forward(self, h, pos, edge_index):\n",
    "        # Start propagating messages.\n",
    "        return self.propagate(edge_index, h=h, pos=pos)\n",
    "\n",
    "    def message(self, h_j, pos_j, pos_i):\n",
    "        # h_j defines the features of neighboring nodes as shape [num_edges, in_channels]\n",
    "        # pos_j defines the position of neighboring nodes as shape [num_edges, 3]\n",
    "        # pos_i defines the position of central nodes as shape [num_edges, 3]\n",
    "\n",
    "        input = pos_j - pos_i  # Compute spatial relation.\n",
    "\n",
    "        if h_j is not None:\n",
    "            # In the first layer, we may not have any hidden node features,\n",
    "            # so we only combine them in case they are present.\n",
    "            input = torch.cat([h_j, input], dim=-1)\n",
    "\n",
    "        return self.mlp(input)  # Apply our final MLP."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_cluster import knn_graph\n",
    "from torch_geometric.nn import global_max_pool\n",
    "\n",
    "\n",
    "class PointNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = PointNetLayer(3, 32)\n",
    "        self.conv2 = PointNetLayer(32, 32)\n",
    "        self.classifier = Linear(32, dataset.num_classes)\n",
    "\n",
    "    def forward(self, pos, batch):\n",
    "        # Compute the kNN graph:\n",
    "        # Here, we need to pass the batch vector to the function call in order\n",
    "        # to prevent creating edges between points of different examples.\n",
    "        # We also add `loop=True` which will add self-loops to the graph in\n",
    "        # order to preserve central point information.\n",
    "        edge_index = knn_graph(pos, k=16, batch=batch, loop=True)\n",
    "\n",
    "        # 3. Start bipartite message passing.\n",
    "        h = self.conv1(h=pos, pos=pos, edge_index=edge_index)\n",
    "        h = h.relu()\n",
    "        h = self.conv2(h=h, pos=pos, edge_index=edge_index)\n",
    "        h = h.relu()\n",
    "\n",
    "        # 4. Global Pooling.\n",
    "        h = global_max_pool(h, batch)  # [num_examples, hidden_channels]\n",
    "\n",
    "        # 5. Classifier.\n",
    "        return self.classifier(h)\n",
    "\n",
    "\n",
    "model = PointNet()\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}